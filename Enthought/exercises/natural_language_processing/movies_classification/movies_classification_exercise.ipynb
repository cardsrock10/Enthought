{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Movies classification exercise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NLTK contains a \"Movie Review\" corpus containing 2000 movie reviews classified in \"positive\" and \"negative\" reviews.\n",
    "\n",
    "In the demo presented during the class, and partially copied below, we used a simple vectorizer and Naive Bayes classifier to learn to classify good and bad movies form reviews.\n",
    "\n",
    "For this exercises, give your best shot at improving the score from the demo (0.83 precision on test data), using every mean you can think about! (Apart from cheating ;-) )."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# A few useful imports.\n",
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style('whitegrid')\n",
    "\n",
    "from nltk.corpus import movie_reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Collect all reviews and their label (\"pos\" or \"neg\") from the corpus.\n",
    "reviews = []\n",
    "labels = []\n",
    "for file_id in movie_reviews.fileids():\n",
    "    reviews.append(movie_reviews.raw(file_id))\n",
    "    labels.append(movie_reviews.categories([file_id])[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# train data points = 1400, # test = 600\n"
     ]
    }
   ],
   "source": [
    "# We set aside 1/3 of the data set to test the classifier. The ranfom state is\n",
    "# fixed, so that everybody will have the same test set.\n",
    "\n",
    "# Divide the data into a training and a test set.\n",
    "from sklearn.cross_validation import train_test_split\n",
    "# Fixed to make the notebook reproducible.\n",
    "random_state = np.random.RandomState(3939)\n",
    "\n",
    "test_set_fraction = 0.3\n",
    "reviews_train, reviews_test, t_train, t_test = train_test_split(\n",
    "    reviews, labels, test_size=test_set_fraction, random_state=random_state)\n",
    "\n",
    "print '# train data points = {}, # test = {}'.format(len(reviews_train), len(reviews_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Here we give the vectorizer / classifier combination shown in the demo.\n",
    "# *** SUBSTITUTE THIS WITH YOUR OWN WORKFLOW ***\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "vectorizer = CountVectorizer(\n",
    "    stop_words='english', lowercase=True, binary=False,\n",
    "    min_df=0.01)\n",
    "features_train = vectorizer.fit_transform(reviews_train)\n",
    "classifier = MultinomialNB()\n",
    "classifier.fit(features_train, t_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision 0.83\n",
      "[[240  46]\n",
      " [ 56 258]]\n"
     ]
    }
   ],
   "source": [
    "# Transform test data and display performance.\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "feature_test = vectorizer.transform(reviews_test)\n",
    "print 'Precision', classifier.score(feature_test, t_test)\n",
    "y_test = classifier.predict(feature_test)\n",
    "print confusion_matrix(t_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 0
}