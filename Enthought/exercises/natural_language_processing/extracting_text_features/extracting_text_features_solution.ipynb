{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracting text features exercise -- Solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The word \"Python\" can refer to both a snake and a programming language.\n",
    "\n",
    "In this exercise, we use the text vectorizers provided in `sklearn` to transform sentences into numerical vectors, and check if sentences using \"Python\" with the same meaning have similar vector representations.\n",
    "\n",
    "1. Use `CountVectorizer` to transform the sentences given below to numerical vectors, and print the result. Only set `lowercase=True` as input argument to `CountVectorizer`. (The output of the vectorizer is a sparse array; use the method `toarray()` to print the result as a regular Numpy array);\n",
    "2. Print the list of extracted features (see the `get_feature_names` method of `CountVectorizer`);\n",
    "3. Compute the pairwise distance between the vector representations of the sentences using the `cosine_distances` function, defined in `sklearn.metrics.pairwise` [1]. Which sentences are closer in the feature space?\n",
    "4. Repeat steps 1-3, removing stopwords (using the `stop_words` optional argument of `CountVectorizer`).\n",
    "5. Repeat steps 1-3 using a `TfidfVectorizer`.\n",
    "6. Finally, use `CountVectorizer` using your own processing method, including tokenization, normalization, and stemming (use the `analyzer` argument of `CountVectorizer` to use your processing method, as discussed in the class slides).\n",
    "\n",
    "[1] `cosine_distances` is a distance measure that is independent of the length of the vectors, see http://bit.ly/1DcbLZx for a detailed description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.set_printoptions(precision=4, suppress=True)\n",
    "\n",
    "import nltk\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_distances\n",
    "\n",
    "documents = [\n",
    "   'Pythons are non-venomous but dangerous snakes.',\n",
    "   'Python is a great programming language!',\n",
    "   'A Python is a constricting snake.',\n",
    "   'Python and Matlab are popular languages in science.',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 1. Create a count vectorizer.\n",
    "vectorizer = CountVectorizer(lowercase=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 1 1 0 1 0 0 0 0 0 0 1 0 0 0 1 0 0 1 1]\n",
      " [0 0 0 0 0 1 0 1 1 0 0 0 0 1 1 0 0 0 0 0]\n",
      " [0 0 0 1 0 0 0 1 0 0 0 0 0 0 1 0 0 1 0 0]\n",
      " [1 1 0 0 0 0 1 0 0 1 1 0 1 0 1 0 1 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "# Train the vectorizer and transform the documents in a single step.\n",
    "features = vectorizer.fit_transform(documents)\n",
    "print features.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'and', u'are', u'but', u'constricting', u'dangerous', u'great', u'in', u'is', u'language', u'languages', u'matlab', u'non', u'popular', u'programming', u'python', u'pythons', u'science', u'snake', u'snakes', u'venomous']\n"
     ]
    }
   ],
   "source": [
    "# 2. Show the extracted features.\n",
    "print vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.      1.      1.      0.8664]\n",
      " [ 1.      0.      0.5528  0.8419]\n",
      " [ 1.      0.5528  0.      0.8232]\n",
      " [ 0.8664  0.8419  0.8232  0.    ]]\n"
     ]
    }
   ],
   "source": [
    "# 3. Compute the matrix of pairwise distances.\n",
    "print cosine_distances(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.      1.      1.      1.    ]\n",
      " [ 1.      0.      0.7113  0.7764]\n",
      " [ 1.      0.7113 -0.      0.7418]\n",
      " [ 1.      0.7764  0.7418  0.    ]]\n"
     ]
    }
   ],
   "source": [
    "# 4. Re-run the analysis after removing stopwords.\n",
    "vectorizer = CountVectorizer(lowercase=True, stop_words='english')\n",
    "features = vectorizer.fit_transform(documents).toarray()\n",
    "print cosine_distances(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.      1.      1.      1.    ]\n",
      " [ 1.     -0.      0.8578  0.8949]\n",
      " [ 1.      0.8578 -0.      0.8749]\n",
      " [ 1.      0.8949  0.8749 -0.    ]]\n"
     ]
    }
   ],
   "source": [
    "# 4. Re-run the analysis with a TF-IFD vectorizer.\n",
    "vectorizer = TfidfVectorizer(lowercase=True, stop_words='english')\n",
    "features = vectorizer.fit_transform(documents).toarray()\n",
    "print cosine_distances(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1.9162907318741551, u'constricting'),\n",
       " (1.9162907318741551, u'dangerous'),\n",
       " (1.9162907318741551, u'great'),\n",
       " (1.9162907318741551, u'language'),\n",
       " (1.9162907318741551, u'languages'),\n",
       " (1.9162907318741551, u'matlab'),\n",
       " (1.9162907318741551, u'non'),\n",
       " (1.9162907318741551, u'popular'),\n",
       " (1.9162907318741551, u'programming'),\n",
       " (1.2231435513142097, u'python'),\n",
       " (1.9162907318741551, u'pythons'),\n",
       " (1.9162907318741551, u'science'),\n",
       " (1.9162907318741551, u'snake'),\n",
       " (1.9162907318741551, u'snakes'),\n",
       " (1.9162907318741551, u'venomous')]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " zip(vectorizer.idf_, vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.      0.7764  0.4836  0.8   ]\n",
      " [ 0.7764  0.      0.7113  0.5528]\n",
      " [ 0.4836  0.7113 -0.      0.7418]\n",
      " [ 0.8     0.5528  0.7418  0.    ]]\n"
     ]
    }
   ],
   "source": [
    "# 4. Re-run the analysis with a custom analysis method, including stemming.\n",
    "from string import punctuation\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "def stemming_analyzer(raw):\n",
    "    tokens = nltk.wordpunct_tokenize(raw)\n",
    "    tokens = [w.strip(punctuation).lower() for w in tokens if w not in punctuation]\n",
    "    tokens = [w for w in tokens if w not in stopwords.words('english')]\n",
    "    stemmer=nltk.PorterStemmer()\n",
    "    return [stemmer.stem(w) for w in tokens]\n",
    "\n",
    "vectorizer = CountVectorizer(analyzer=stemming_analyzer)\n",
    "features = vectorizer.fit_transform(documents).toarray()\n",
    "print cosine_distances(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'constrict',\n",
       " u'danger',\n",
       " u'great',\n",
       " u'languag',\n",
       " u'matlab',\n",
       " u'non',\n",
       " u'popular',\n",
       " u'program',\n",
       " u'python',\n",
       " u'scienc',\n",
       " u'snake',\n",
       " u'venom']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 0
}